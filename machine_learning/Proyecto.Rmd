---
title: "Untitled"
author: "jene"
date: "31 de mayo de 2019"
output: html_document
---
##introducción

Este proyecto utiliza el DataSet de ejercicios de levantamiento de pesas para desarrollar y probar un modelo de reconocimiento/predicción de actividad humana. En particular, el objetivo de este proyecto es reconocer/predecir la manera en que los usuarios de un conjunto de sensores corporales hicieron el ejercicio de levantamiento de pesas. Procesará los datos de acelerómetros en la banda, antebrazo, brazo y Dumbell de 6 participantes que realizaron barbell ascensores correctamente y de forma incorrecta de 5 maneras diferentes.


```
library(knitr)
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(doParallel)
library(dplyr)
##install.packages("dplyr")

```
#Lendod los datos

```
training <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-training.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
testing <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-testing.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
dim(training)

```
#  Limpieza de los datos
elimanado los espacios en blanco y los nA


```
sapply(X=training, FUN = function(d){sum(is.na(d))}) 
data_clean <- function(dat){
  
  dat <- subset(dat, select = -c(X, 
                                 user_name,
                                 raw_timestamp_part_1,
                                 raw_timestamp_part_2,
                                 cvtd_timestamp,
                                 new_window,
                                 num_window))  
  dat <- dat[,sapply(X=dat, FUN = function(d){sum(is.na(d))}) == 0]
  return(dat)
}


training <- data_clean(training)
testing <- data_clean(testing)
```

## division de los datos 

Aquí divido los datos del tren en dos subgrupos: un sub-entrenamiento (70%) y un sub-test (30%) conjuntos de sata.

```{r partition, cache=TRUE}

indexTrain <- createDataPartition(y = training$classe, p=0.75, list = FALSE)
train <- training[indexTrain,]
test <- training[-indexTrain,]
dim(train)
```{r partition, cache=TRUE}

#PrediccioN
Ladistribución de la variable de resultado, que está en una escala nominal de 5 niveles y no parece tener ninguna anormalidad
```
training %>%
  ggplot(aes(x=classe)) +  geom_bar()+labs(title = "Distribución del resultados")
```

## Prediccion con clasificacion tres


Aquí construyo un modelo de árbol con una validación cruzada de 5 pliegues 
```
tr_control <- trainControl(method="cv", number = 5)
model_tree <- train(classe ~ ., data = train, method = "rpart", trControl = tr_control)
fancyRpartPlot(model_tree$finalModel)

pred_train <- predict(model_tree, newdata = train)
confMatrix_train <- confusionMatrix(train$classe, pred_train)
confMatrix_train$table
confMatrix_train$overall[1]

pred_test <- predict(model_tree, newdata = test)
confMatrix_test <- confusionMatrix(test$classe, pred_test)
confMatrix_test$table
confMatrix_test$overall[1]

```
## Predicción de los datos 
Aquí trato de hacer una predicción sobre los datos de las pruebas con dos modelos obtenidos donde se compara 
`` `{r testdata, cache = TRUE}
predecir (model_forest, newdata = test_data)
predecir (model_boost, newdata = test_data)
`` `
Los resultados obtenidos son iguales, lo que me da una esperanza de que mi predicción de Clases para los datos de prueba será precisa.

## Conclusión


El árbol de clasificación El resulatodo era muy pobare  debido a los usos de muchas variables

El Gradient Boosting Regression obtuvo un muy buen resultado,
El Random Forests es el mas optimo


